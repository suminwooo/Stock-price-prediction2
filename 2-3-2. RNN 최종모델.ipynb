{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('data/class.csv')\n",
    "code_list=[]\n",
    "for i in [i for i in data.columns[1:]]:\n",
    "    code_list.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data var ##\n",
    "code = 'a5930'\n",
    "n_test_set = 10 # 20개는 테스트 셋 사용할 갯수\n",
    "est_data = 2 # n 개의 단어를 잘라줌(n개를 예측하는 모형)\n",
    "batch_size = 5 #한번에 5개의 데이터를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 4 steps\n",
      "Epoch 1/100\n",
      "4/4 - 3s - loss: 2.7742 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "4/4 - 0s - loss: 2.7657 - accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "4/4 - 0s - loss: 2.7583 - accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "4/4 - 0s - loss: 2.7497 - accuracy: 0.1000\n",
      "Epoch 5/100\n",
      "4/4 - 0s - loss: 2.7394 - accuracy: 0.1000\n",
      "Epoch 6/100\n",
      "4/4 - 0s - loss: 2.7218 - accuracy: 0.1000\n",
      "Epoch 7/100\n",
      "4/4 - 0s - loss: 2.6992 - accuracy: 0.1000\n",
      "Epoch 8/100\n",
      "4/4 - 0s - loss: 2.6703 - accuracy: 0.1000\n",
      "Epoch 9/100\n",
      "4/4 - 0s - loss: 2.6130 - accuracy: 0.1000\n",
      "Epoch 10/100\n",
      "4/4 - 0s - loss: 2.5393 - accuracy: 0.1000\n",
      "Epoch 11/100\n",
      "4/4 - 0s - loss: 2.4942 - accuracy: 0.1000\n",
      "Epoch 12/100\n",
      "4/4 - 0s - loss: 2.4495 - accuracy: 0.1000\n",
      "Epoch 13/100\n",
      "4/4 - 0s - loss: 2.4328 - accuracy: 0.1000\n",
      "Epoch 14/100\n",
      "4/4 - 0s - loss: 2.4039 - accuracy: 0.1500\n",
      "Epoch 15/100\n",
      "4/4 - 0s - loss: 2.3729 - accuracy: 0.1500\n",
      "Epoch 16/100\n",
      "4/4 - 0s - loss: 2.3794 - accuracy: 0.1500\n",
      "Epoch 17/100\n",
      "4/4 - 0s - loss: 2.3596 - accuracy: 0.1000\n",
      "Epoch 18/100\n",
      "4/4 - 0s - loss: 2.3527 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "4/4 - 0s - loss: 2.3440 - accuracy: 0.3000\n",
      "Epoch 20/100\n",
      "4/4 - 0s - loss: 2.3470 - accuracy: 0.1500\n",
      "Epoch 21/100\n",
      "4/4 - 0s - loss: 2.3269 - accuracy: 0.1500\n",
      "Epoch 22/100\n",
      "4/4 - 0s - loss: 2.3079 - accuracy: 0.2000\n",
      "Epoch 23/100\n",
      "4/4 - 0s - loss: 2.3158 - accuracy: 0.2500\n",
      "Epoch 24/100\n",
      "4/4 - 0s - loss: 2.2902 - accuracy: 0.2500\n",
      "Epoch 25/100\n",
      "4/4 - 0s - loss: 2.2892 - accuracy: 0.1000\n",
      "Epoch 26/100\n",
      "4/4 - 0s - loss: 2.2644 - accuracy: 0.1000\n",
      "Epoch 27/100\n",
      "4/4 - 0s - loss: 2.2152 - accuracy: 0.2000\n",
      "Epoch 28/100\n",
      "4/4 - 0s - loss: 2.1782 - accuracy: 0.2500\n",
      "Epoch 29/100\n",
      "4/4 - 0s - loss: 2.1349 - accuracy: 0.2000\n",
      "Epoch 30/100\n",
      "4/4 - 0s - loss: 2.0904 - accuracy: 0.2500\n",
      "Epoch 31/100\n",
      "4/4 - 0s - loss: 2.0408 - accuracy: 0.2500\n",
      "Epoch 32/100\n",
      "4/4 - 0s - loss: 1.9987 - accuracy: 0.2500\n",
      "Epoch 33/100\n",
      "4/4 - 0s - loss: 1.9448 - accuracy: 0.3500\n",
      "Epoch 34/100\n",
      "4/4 - 0s - loss: 1.9184 - accuracy: 0.3000\n",
      "Epoch 35/100\n",
      "4/4 - 0s - loss: 1.8670 - accuracy: 0.1500\n",
      "Epoch 36/100\n",
      "4/4 - 0s - loss: 1.8336 - accuracy: 0.2500\n",
      "Epoch 37/100\n",
      "4/4 - 0s - loss: 1.8030 - accuracy: 0.3500\n",
      "Epoch 38/100\n",
      "4/4 - 0s - loss: 1.7483 - accuracy: 0.3000\n",
      "Epoch 39/100\n",
      "4/4 - 0s - loss: 1.7183 - accuracy: 0.2500\n",
      "Epoch 40/100\n",
      "4/4 - 0s - loss: 1.6829 - accuracy: 0.4000\n",
      "Epoch 41/100\n",
      "4/4 - 0s - loss: 1.6297 - accuracy: 0.4500\n",
      "Epoch 42/100\n",
      "4/4 - 0s - loss: 1.5912 - accuracy: 0.4500\n",
      "Epoch 43/100\n",
      "4/4 - 0s - loss: 1.5649 - accuracy: 0.4000\n",
      "Epoch 44/100\n",
      "4/4 - 0s - loss: 1.5427 - accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "4/4 - 0s - loss: 1.5227 - accuracy: 0.5500\n",
      "Epoch 46/100\n",
      "4/4 - 0s - loss: 1.4966 - accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "4/4 - 0s - loss: 1.4598 - accuracy: 0.4500\n",
      "Epoch 48/100\n",
      "4/4 - 0s - loss: 1.4299 - accuracy: 0.5500\n",
      "Epoch 49/100\n",
      "4/4 - 0s - loss: 1.4186 - accuracy: 0.5500\n",
      "Epoch 50/100\n",
      "4/4 - 0s - loss: 1.3924 - accuracy: 0.5500\n",
      "Epoch 51/100\n",
      "4/4 - 0s - loss: 1.3575 - accuracy: 0.5500\n",
      "Epoch 52/100\n",
      "4/4 - 0s - loss: 1.3596 - accuracy: 0.5500\n",
      "Epoch 53/100\n",
      "4/4 - 0s - loss: 1.3055 - accuracy: 0.6000\n",
      "Epoch 54/100\n",
      "4/4 - 0s - loss: 1.2707 - accuracy: 0.5500\n",
      "Epoch 55/100\n",
      "4/4 - 0s - loss: 1.2065 - accuracy: 0.5500\n",
      "Epoch 56/100\n",
      "4/4 - 0s - loss: 1.2174 - accuracy: 0.6000\n",
      "Epoch 57/100\n",
      "4/4 - 0s - loss: 1.1832 - accuracy: 0.6500\n",
      "Epoch 58/100\n",
      "4/4 - 0s - loss: 1.1741 - accuracy: 0.7000\n",
      "Epoch 59/100\n",
      "4/4 - 0s - loss: 1.1129 - accuracy: 0.7000\n",
      "Epoch 60/100\n",
      "4/4 - 0s - loss: 1.1153 - accuracy: 0.7000\n",
      "Epoch 61/100\n",
      "4/4 - 0s - loss: 1.0721 - accuracy: 0.7000\n",
      "Epoch 62/100\n",
      "4/4 - 0s - loss: 1.0584 - accuracy: 0.7000\n",
      "Epoch 63/100\n",
      "4/4 - 0s - loss: 1.0193 - accuracy: 0.7000\n",
      "Epoch 64/100\n",
      "4/4 - 0s - loss: 0.9805 - accuracy: 0.7000\n",
      "Epoch 65/100\n",
      "4/4 - 0s - loss: 0.9660 - accuracy: 0.7000\n",
      "Epoch 66/100\n",
      "4/4 - 0s - loss: 1.1092 - accuracy: 0.6000\n",
      "Epoch 67/100\n",
      "4/4 - 0s - loss: 1.0019 - accuracy: 0.7000\n",
      "Epoch 68/100\n",
      "4/4 - 0s - loss: 1.0361 - accuracy: 0.7000\n",
      "Epoch 69/100\n",
      "4/4 - 0s - loss: 0.9787 - accuracy: 0.8000\n",
      "Epoch 70/100\n",
      "4/4 - 0s - loss: 0.9432 - accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "4/4 - 0s - loss: 0.9130 - accuracy: 0.8500\n",
      "Epoch 72/100\n",
      "4/4 - 0s - loss: 0.8194 - accuracy: 0.9500\n",
      "Epoch 73/100\n",
      "4/4 - 0s - loss: 0.8189 - accuracy: 0.8000\n",
      "Epoch 74/100\n",
      "4/4 - 0s - loss: 0.7952 - accuracy: 0.9000\n",
      "Epoch 75/100\n",
      "4/4 - 0s - loss: 0.7532 - accuracy: 0.9000\n",
      "Epoch 76/100\n",
      "4/4 - 0s - loss: 0.7642 - accuracy: 0.8500\n",
      "Epoch 77/100\n",
      "4/4 - 0s - loss: 0.7150 - accuracy: 0.9000\n",
      "Epoch 78/100\n",
      "4/4 - 0s - loss: 0.6837 - accuracy: 0.9500\n",
      "Epoch 79/100\n",
      "4/4 - 0s - loss: 0.6870 - accuracy: 0.9000\n",
      "Epoch 80/100\n",
      "4/4 - 0s - loss: 0.6679 - accuracy: 0.9500\n",
      "Epoch 81/100\n",
      "4/4 - 0s - loss: 0.6516 - accuracy: 0.9000\n",
      "Epoch 82/100\n",
      "4/4 - 0s - loss: 0.6238 - accuracy: 0.9500\n",
      "Epoch 83/100\n",
      "4/4 - 0s - loss: 0.6479 - accuracy: 0.9500\n",
      "Epoch 84/100\n",
      "4/4 - 0s - loss: 0.6263 - accuracy: 0.9500\n",
      "Epoch 85/100\n",
      "4/4 - 0s - loss: 0.7060 - accuracy: 0.8500\n",
      "Epoch 86/100\n",
      "4/4 - 0s - loss: 1.0484 - accuracy: 0.6000\n",
      "Epoch 87/100\n",
      "4/4 - 0s - loss: 0.9045 - accuracy: 0.7000\n",
      "Epoch 88/100\n",
      "4/4 - 0s - loss: 0.8524 - accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "4/4 - 0s - loss: 0.9526 - accuracy: 0.7000\n",
      "Epoch 90/100\n",
      "4/4 - 0s - loss: 0.8379 - accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "4/4 - 0s - loss: 0.8526 - accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "4/4 - 0s - loss: 0.8549 - accuracy: 0.8000\n",
      "Epoch 93/100\n",
      "4/4 - 0s - loss: 0.7157 - accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "4/4 - 0s - loss: 0.6770 - accuracy: 0.8500\n",
      "Epoch 95/100\n",
      "4/4 - 0s - loss: 0.6937 - accuracy: 0.7500\n",
      "Epoch 96/100\n",
      "4/4 - 0s - loss: 0.7780 - accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "4/4 - 0s - loss: 0.6751 - accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "4/4 - 0s - loss: 0.6901 - accuracy: 0.8000\n",
      "Epoch 99/100\n",
      "4/4 - 0s - loss: 0.5811 - accuracy: 0.8500\n",
      "Epoch 100/100\n",
      "4/4 - 0s - loss: 0.5430 - accuracy: 0.8500\n"
     ]
    }
   ],
   "source": [
    "train = np.array(data[code][:-n_test_set]) \n",
    "test = data[-n_test_set:-est_data][code]\n",
    "class_set = sorted(set(train)) \n",
    "class_set.append('NO')\n",
    "word_idx = {u:i for i, u in enumerate(class_set)}\n",
    "idx_word = np.array(class_set)\n",
    "text_as_int = np.array([word_idx[c] for c in train])\n",
    "seq_length = n_test_set \n",
    "examples_per_epoch = len(text_as_int) // seq_length\n",
    "sentence_dataset = tf.data.Dataset.from_tensor_slices(text_as_int) \n",
    "sentence_dataset = sentence_dataset.batch(seq_length+est_data, drop_remainder=True) \n",
    "def split(data): \n",
    "    return [data[:-est_data], data[-est_data]]\n",
    "train_dataset = sentence_dataset.map(split) \n",
    "BATCH_SIZE = batch_size \n",
    "steps_per_epoch = examples_per_epoch // BATCH_SIZE\n",
    "BUFFER_SIZE = 10000\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "total_words = len(class_set)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(total_words,n_test_set, input_length=seq_length),\n",
    "    tf.keras.layers.LSTM(units=64, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.LSTM(units=32),\n",
    "    tf.keras.layers.Dense(total_words, activation='softmax')])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "def testmodel(epoch, logs):\n",
    "    if epoch % 5 != 0 and epoch != 49:\n",
    "        return\n",
    "    test_sentence = data[code][-n_test_set:]\n",
    "    next_words = est_data\n",
    "    for _ in range(next_words):\n",
    "        test_text_X = test_sentence[-seq_length:]\n",
    "        test_text_X = np.array([word_idx[c] if c in word_idx else word_idx['NO'] for c in test_text_X])\n",
    "        test_text_X = pad_sequences([test_text_X], maxlen=seq_length, padding='pre', value=word_idx['NO'])\n",
    "        output_idx = model.predict_classes(test_text_X)\n",
    "        test_sentence += ' ' + idx_word[output_idx[0]]\n",
    "testmodelcb = tf.keras.callbacks.LambdaCallback(on_epoch_end=testmodel)\n",
    "history = model.fit(train_dataset.repeat(), epochs=100, steps_per_epoch=steps_per_epoch, callbacks=[testmodelcb], verbose=2)\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "next_class = est_data\n",
    "for _ in range(next_class):\n",
    "    test_text_X = test_sentence.split(' ')[-seq_length:]\n",
    "    test_text_X = np.array([word_idx[c] if c in word_idx else word_idx['NO'] for c in test_text_X])\n",
    "    test_text_X = pad_sequences([test_text_X], maxlen=seq_length, padding='pre', value=word_idx['NO'])\n",
    "    output_idx = model.predict_classes(test_text_X)\n",
    "    test_sentence += ' ' + idx_word[output_idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,5번 값 = 예측값\n",
      "predict data >>>  c20 c20 c18 c18 c08\n",
      "actual data  >>>  c25 c08 c20 c11 c01\n"
     ]
    }
   ],
   "source": [
    "print('4,5번 값 = 예측값')\n",
    "print('predict data >>>',test_sentence[-20:])\n",
    "print('actual data  >>>','', str(data['a28260'][-5:].tolist()).replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"\").replace(\"'\",\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
