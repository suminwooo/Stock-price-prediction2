{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "data = pd.read_csv('data/class.csv')\n",
    "code_list=[]\n",
    "for i in [i for i in data.columns[1:]]:\n",
    "    code_list.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data var ##\n",
    "code = 'a5930'\n",
    "n_test_set = 10 # 20개는 테스트 셋 사용할 갯수\n",
    "est_data = 2 # n 개의 단어를 잘라줌(n개를 예측하는 모형)\n",
    "batch_size = 5 #한번에 5개의 데이터를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 4 steps\n",
      "Epoch 1/10\n",
      "4/4 - 3s - loss: 2.7724 - accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "4/4 - 0s - loss: 2.7632 - accuracy: 0.2000\n",
      "Epoch 3/10\n",
      "4/4 - 0s - loss: 2.7514 - accuracy: 0.1500\n",
      "Epoch 4/10\n",
      "4/4 - 0s - loss: 2.7387 - accuracy: 0.1500\n",
      "Epoch 5/10\n",
      "4/4 - 0s - loss: 2.7216 - accuracy: 0.1500\n",
      "Epoch 6/10\n",
      "4/4 - 0s - loss: 2.6965 - accuracy: 0.1500\n",
      "Epoch 7/10\n",
      "4/4 - 0s - loss: 2.6532 - accuracy: 0.1500\n",
      "Epoch 8/10\n",
      "4/4 - 0s - loss: 2.5993 - accuracy: 0.1500\n",
      "Epoch 9/10\n",
      "4/4 - 0s - loss: 2.5114 - accuracy: 0.1500\n",
      "Epoch 10/10\n",
      "4/4 - 0s - loss: 2.4623 - accuracy: 0.1500\n"
     ]
    }
   ],
   "source": [
    "train = np.array(data[code][:-n_test_set]) \n",
    "test = data[-n_test_set:-est_data][code]\n",
    "class_set = sorted(set(train)) \n",
    "class_set.append('NO')\n",
    "word_idx = {u:i for i, u in enumerate(class_set)}\n",
    "idx_word = np.array(class_set)\n",
    "text_as_int = np.array([word_idx[c] for c in train])\n",
    "seq_length = n_test_set \n",
    "examples_per_epoch = len(text_as_int) // seq_length\n",
    "sentence_dataset = tf.data.Dataset.from_tensor_slices(text_as_int) \n",
    "sentence_dataset = sentence_dataset.batch(seq_length+est_data, drop_remainder=True) \n",
    "def split(data): \n",
    "    return [data[:-est_data], data[-est_data]]\n",
    "train_dataset = sentence_dataset.map(split) \n",
    "BATCH_SIZE = batch_size \n",
    "steps_per_epoch = examples_per_epoch // BATCH_SIZE\n",
    "BUFFER_SIZE = 10000\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "total_words = len(class_set)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(total_words,n_test_set, input_length=seq_length),\n",
    "    tf.keras.layers.LSTM(units=64, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.LSTM(units=32),\n",
    "    tf.keras.layers.Dense(total_words, activation='softmax')])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "def testmodel(epoch, logs):\n",
    "    if epoch % 5 != 0 and epoch != 49:\n",
    "        return\n",
    "    test_sentence = str(data[code][-20:].tolist()).replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"\").replace(\"'\",\"\")\n",
    "\n",
    "    next_words = 5\n",
    "    for _ in range(next_words):\n",
    "        test_text_X = test_sentence[-seq_length:]\n",
    "        test_text_X = np.array([word_idx[c] if c in word_idx else word_idx['NO'] for c in test_text_X])\n",
    "        test_text_X = pad_sequences([test_text_X], maxlen=seq_length, padding='pre', value=word_idx['NO'])\n",
    "\n",
    "        output_idx = model.predict_classes(test_text_X)\n",
    "        test_sentence += ' ' + idx_word[output_idx[0]]\n",
    "testmodelcb = tf.keras.callbacks.LambdaCallback(on_epoch_end=testmodel)\n",
    "history = model.fit(train_dataset.repeat(), epochs=10, steps_per_epoch=steps_per_epoch, callbacks=[testmodelcb], verbose=2)\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "test_sentence = str(data[code][-20:-2].tolist()).replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"\").replace(\"'\",\"\")\n",
    "next_words = 2\n",
    "for _ in range(next_words):\n",
    "    test_text_X = test_sentence.split(' ')[-seq_length:]\n",
    "    test_text_X = np.array([word_idx[c] if c in word_idx else word_idx['NO'] for c in test_text_X])\n",
    "    test_text_X = pad_sequences([test_text_X], maxlen=seq_length, padding='pre', value=word_idx['NO'])\n",
    "    output_idx = model.predict_classes(test_text_X)\n",
    "    test_sentence += ' ' + idx_word[output_idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,5번 값 = 예측값\n",
      "predict data >>>  c23 c01 c23 c13 c13\n",
      "actual data  >>>  c23 c01 c23 c06 c06\n"
     ]
    }
   ],
   "source": [
    "print('4,5번 값 = 예측값')\n",
    "print('predict data >>>',test_sentence[-20:])\n",
    "print('actual data  >>>','', str(data['a5930'][-5:].tolist()).replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"\").replace(\"'\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
